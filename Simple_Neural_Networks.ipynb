{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple Neural Networks.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMyDmS7PwyjgLEa/UGkJres",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meghanaayyala/Machine-Learning/blob/main/Simple_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "A_woyhBn_TNY"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A neuron takes inputs, does some math with them, and produces one output.\n",
        "For example, for a 2 input neuron\n",
        "First, each input is multiplied by a weight: <br>\n",
        "x1=x1*w1 <br>\n",
        "x2=x2*w2 <br>\n",
        "Next, all the weighted inputs are added together with a bias b: <br>\n",
        "(x1*w1)+(x2*w2)+b\n",
        "<br>\n",
        "Finally, the sum is passed through an activation function: \n",
        "<br>\n",
        "y = f((x1*w1)+(x2*w2)+b)\n",
        "<br>\n",
        "Commonly used activation function is the Sigmoid Function:\n",
        "<br>\n",
        "![image.png](data:image/png;base64,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)\n",
        " "
      ],
      "metadata": {
        "id": "wjwBZe02_u_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "  # Sigmoid Function as activation function: f(x) = 1 / (1 + e^(-x))\n",
        "  return 1 / (1 + np.exp(-x))"
      ],
      "metadata": {
        "id": "IKIdpxUn_bkW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# consider the input as a numpy vector X=[x,y]\n",
        "# we define the weights as a vector w=[0,1]\n",
        "# defining the neuron class\n",
        "# defining neuron class\n",
        "class Neuron:\n",
        "  def __init__(self, weights, bias): # constructor for neuron class\n",
        "    self.weights = weights  #initializing the weights\n",
        "    self.bias = bias        #initializing the bias\n",
        "  def feedforward(self, inputs):\n",
        "    # computes the dot product between input vector X (inputs) and weights vector, adds the bias\n",
        "    total = np.dot(self.weights, inputs) + self.bias\n",
        "    # using the activation function and returning output\n",
        "    return sigmoid(total)"
      ],
      "metadata": {
        "id": "gm542cpBBJLB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example neuron\n",
        "w=np.array([0,1])  # weights vector\n",
        "x=np.array([2,3])  # 2 input vector\n",
        "bias=4\n",
        "neuron1=Neuron(w,bias)\n"
      ],
      "metadata": {
        "id": "mWAXtXt_CXTe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(neuron1.feedforward(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVzqTeLpC1zk",
        "outputId": "b866fadc-04c7-4128-b4fc-9cc4a89411ec"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9990889488055994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A neural network is a combination of layers of neurons.\n",
        "<br>\n",
        "A hidden layer is any layer between the input (first) layer and output (last) layer. There can be multiple hidden layers."
      ],
      "metadata": {
        "id": "oZRIIJMJDN0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork:\n",
        "  '''\n",
        "  A neural network with:\n",
        "    - 2 inputs\n",
        "    - a hidden layer with 2 neurons (h1, h2)\n",
        "    - an output layer with 1 neuron (o1)\n",
        "  Each neuron has the same weights and bias:\n",
        "    - w = [0, 1]\n",
        "    - b = 0\n",
        "  '''\n",
        "  def __init__(self):\n",
        "    weights = np.array([0, 1])\n",
        "    bias = 0\n",
        "    self.h1=Neuron(weights,bias)\n",
        "    self.h2=Neuron(weights,bias)\n",
        "    self.o1 = Neuron(weights, bias)\n",
        "\n",
        "  def feedforward(self, x):\n",
        "    out_h1 = self.h1.feedforward(x)\n",
        "    out_h2 = self.h2.feedforward(x)\n",
        "\n",
        "    # The inputs for o1 are the outputs from h1 and h2\n",
        "    out_o1 = self.o1.feedforward(np.array([out_h1, out_h2]))\n",
        "\n",
        "    return out_o1"
      ],
      "metadata": {
        "id": "53puEjnbC35j"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network1=NeuralNetwork()"
      ],
      "metadata": {
        "id": "x18zLC1JEJTR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([2, 3])\n",
        "print(network1.feedforward(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSPQ17F8EMCF",
        "outputId": "af711991-c45e-4b65-eaf3-b3ae201eb302"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7216325609518421\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qHK8maHtEN8W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}